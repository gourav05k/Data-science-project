import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')

dataset = pd.read_csv(r"C:\Users\Gourav Kamboj\OneDrive\Desktop\DS_DATASET.csv") # read data from local computer
#checking missing data
dataset.isnull().sum().sort_values(ascending=False)

# drop columns that we don't need including those having missing values more than 50%
col_drop = ['First Name','Last Name','DOB [DD/MM/YYYY]','Current Employment Status','State','Zip Code','Gender','Email Address','Contact Number','Emergency Contact Number','University Name','Course Type','link to Linkedin profile','Link to updated Resume (Google/ One Drive link preferred)', 'Certifications/Achievement/ Research papers']
dataset.drop(col_drop, axis=1, inplace=True)

# strip the trailing and leading spaces
dataset['Areas of interest'] = dataset['Areas of interest'].str.strip()

# Splitting the attributes into independent and dependent attributes
label_encode = {'Label':{'ineligible': 0, 'eligible': 1}}   #'Current Employment Status':{'Student': 1},
dataset.replace(label_encode, inplace=True)

X = dataset.iloc[:,:-1].values # attributes to determine dependent variable

labelencoder_X = LabelEncoder()   # label encoding
X[:,0]  = labelencoder_X.fit_transform(X[:,0])
for i in range(2,6):
    X[:,i]  = labelencoder_X.fit_transform(X[:,i])
for i in range(8,13):
    X[:,i]  = labelencoder_X.fit_transform(X[:,i])
X[:,15]  = labelencoder_X.fit_transform(X[:,15])

Y = dataset.iloc[:,-1].values # dependent(target) variable
#normalization
X_max = np.max(X, axis=0)
X_min = np.min(X, axis=0)
X_min,X_max
X=(X-X_min)/(X_max-X_min) 

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20)

#version 2 (SVM)

from sklearn.svm import SVC
svclassifier = SVC(kernel='linear')
svclassifier.fit(X_train, Y_train)
Y_pred = svclassifier.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

cnf_mat_svm = confusion_matrix(Y_test,Y_pred)
svm_report = classification_report(Y_test,Y_pred)
fig, ax = plt.subplots()
tick_marks = np.arange(len('Label'))
plt.xticks(tick_marks, 'Label')
plt.yticks(tick_marks, 'Label')
sns.heatmap(pd.DataFrame(cnf_mat_svm), annot=True, cmap="viridis" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', Y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
print(cnf_mat_svm)
print(svm_report)
print("Accuracy:",metrics.accuracy_score(Y_test, Y_pred))
print("Precision:",metrics.precision_score(Y_test, Y_pred))
print("Recall:",metrics.recall_score(Y_test, Y_pred))
